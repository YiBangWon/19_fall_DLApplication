{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9vfEe1lbS_89"
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "N9yOOf9jUlje",
    "outputId": "025d96c2-91a0-4ced-d562-c86e49e36767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.910\n",
      "Test score: 0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, random_state=0)\n",
    "\n",
    "#logi_reg = LogisticRegression().fit(X_train,y_train)\n",
    "#print(\"Training accuracy = \", logi_reg.score(X_train, y_train))\n",
    "#print(\"Test Accuracy = \", logi_reg.score(X_test, y_test))\n",
    "\n",
    "#logreg100 = LogisticRegression(C=100).fit(X_train, y_train)\n",
    "#print(\"Training score: {:.3f}\".format(logreg100.score(X_train, y_train)))\n",
    "#print(\"Test score: {:.3f}\".format(logreg100.score(X_test, y_test)))\n",
    "\n",
    "logreg001 = LogisticRegression(C=0.01).fit(X_train, y_train)\n",
    "print(\"Training score: {:.3f}\".format(logreg001.score(X_train, y_train)))\n",
    "print(\"Test score: {:.3f}\".format(logreg001.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuVxNkYtVL90"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#linearSVC = LinearSVC().fit(X_train,y_train)\n",
    "\n",
    "#print(\"Training accuracy = \", linearSVC.score(X_train, y_train))\n",
    "#print(\"Test Accuracy = \", linearSVC.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "qmjDcB82X8o4",
    "outputId": "124e7bed-bf1d-42c5-c3b0-793c11ad7b40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:  0.9774436090225563\n",
      "Accuracy on test set:  0.9777777777777777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "min_on_training = X_train.min(axis=0) #x_train은 569 x 30인 2차원 디메젼이지, 그 중 axis가 0라는 것은 첫번째 차원(세로차원,row)의 얘기. 이 중 min을 찾아라\n",
    "max_on_training = X_train.max(axis=0) #x_train은 2차원 디메젼이지, 그 중 axis가 0라는 것은 첫번째 차원(세로차원,row)의 얘기. 이 중 각 feature의 max를 찾아라\n",
    "\n",
    "# prevent divison by zero\n",
    "norm_range = max_on_training - min_on_training #max와 min의 차이 구하기. 1x30 shape\n",
    "norm_range[norm_range == 0] = 1  #분모가 0이 되는 경우를 체크하는 것. 바이너리 변수를 어레이어 넣으면 각 어레이마다 true,false를 검사한다\n",
    "\n",
    "# subtract the min, and divide by range\n",
    "X_train_scaled = ((X_train - min_on_training) / norm_range) * 2\n",
    "X_test_scaled = ((X_test - min_on_training) / norm_range) * 2\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train_scaled, y_train)  #y에 대해서는 normalization을 안 했다. y는 어차피 0,1이다.\n",
    "print(\"Accuracy on training set: \",format(svc.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: \",format(svc.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "Wm7XXXZQYU6w",
    "outputId": "2a060456-dde2-4c93-8861-1635e893b17b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy =  1.0\n",
      "Test Accuracy =  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mean_on_train = X_train.mean(axis=0)\n",
    "std_on_train = X_train.std(axis=0)\n",
    "\n",
    "std_on_train[std_on_train == 0] = 1\n",
    "\n",
    "X_train_scaled = (X_train - mean_on_train) / std_on_train \n",
    "X_test_scaled = (X_test - mean_on_train) / std_on_train \n",
    "\n",
    "\n",
    "mlp = MLPClassifier(random_state=0)\n",
    "mlp.fit(X_train, y_train)   \n",
    "\n",
    "print(\"Training accuracy = \", mlp.score(X_train, y_train))\n",
    "print(\"Test Accuracy = \", mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW2_P2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
